{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries first. Run this in a cell if not installed.\n",
    "# !pip install langchain wikipedia-api duckduckgo-search python-docx\n",
    "\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.chains import SimpleChain\n",
    "import os\n",
    "\n",
    "# Tool 1: Wikipedia Search Tool\n",
    "class WikipediaSearchTool:\n",
    "    def __init__(self):\n",
    "        self.tool = WikipediaQueryRun()\n",
    "        \n",
    "    def search(self, query):\n",
    "        return self.tool.run(query)\n",
    "\n",
    "# Tool 2: DuckDuckGo Search Tool\n",
    "class DuckDuckGoSearchTool:\n",
    "    def __init__(self):\n",
    "        self.tool = DuckDuckGoSearchResults()\n",
    "    \n",
    "    def search(self, query):\n",
    "        return self.tool.run(query)\n",
    "\n",
    "# Tool 3: Web Scraping Tool\n",
    "class WebScraperTool:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def scrape(self, url):\n",
    "        loader = WebBaseLoader(url)\n",
    "        return loader.load()\n",
    "\n",
    "# Tool 4: Save to .txt file Tool\n",
    "class SaveToTextFileTool:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def save(self, filename, content):\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "\n",
    "# Research AI Agent\n",
    "class ResearchAgent:\n",
    "    def __init__(self):\n",
    "        self.wikipedia_tool = WikipediaSearchTool()\n",
    "        self.duckduckgo_tool = DuckDuckGoSearchTool()\n",
    "        self.web_scraper_tool = WebScraperTool()\n",
    "        self.save_tool = SaveToTextFileTool()\n",
    "    \n",
    "    def run(self, query):\n",
    "        # Step 1: Search in Wikipedia\n",
    "        print(f\"Searching Wikipedia for: {query}\")\n",
    "        wikipedia_result = self.wikipedia_tool.search(query)\n",
    "        \n",
    "        # Step 2: If no Wikipedia result, try DuckDuckGo\n",
    "        if not wikipedia_result:\n",
    "            print(\"No results from Wikipedia, searching DuckDuckGo...\")\n",
    "            duckduckgo_results = self.duckduckgo_tool.search(query)\n",
    "            \n",
    "            # Step 3: If DuckDuckGo finds a website, scrape the content\n",
    "            if duckduckgo_results and 'link' in duckduckgo_results[0]:\n",
    "                url = duckduckgo_results[0]['link']\n",
    "                print(f\"Scraping website: {url}\")\n",
    "                website_content = self.web_scraper_tool.scrape(url)\n",
    "                full_text = '\\n'.join([doc.page_content for doc in website_content])\n",
    "            else:\n",
    "                full_text = \"No content found from DuckDuckGo search results.\"\n",
    "        else:\n",
    "            full_text = wikipedia_result\n",
    "        \n",
    "        # Step 4: Save the result to a .txt file\n",
    "        filename = \"research_result.txt\"\n",
    "        print(f\"Saving research to {filename}\")\n",
    "        self.save_tool.save(filename, full_text)\n",
    "        print(f\"Research saved successfully to {filename}\")\n",
    "\n",
    "# Initialize and run the agent\n",
    "agent = ResearchAgent()\n",
    "agent.run(\"Research about the XZ backdoor\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
