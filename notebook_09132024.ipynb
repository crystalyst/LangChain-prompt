# Install necessary libraries first. Run this in a cell if not installed.
# !pip install langchain wikipedia-api duckduckgo-search python-docx

from langchain.tools import WikipediaQueryRun
from langchain.tools import DuckDuckGoSearchResults
from langchain.document_loaders import WebBaseLoader
from langchain.chains import SimpleChain
import os

# Tool 1: Wikipedia Search Tool
class WikipediaSearchTool:
    def __init__(self):
        self.tool = WikipediaQueryRun()
        
    def search(self, query):
        return self.tool.run(query)

# Tool 2: DuckDuckGo Search Tool
class DuckDuckGoSearchTool:
    def __init__(self):
        self.tool = DuckDuckGoSearchResults()
    
    def search(self, query):
        return self.tool.run(query)

# Tool 3: Web Scraping Tool
class WebScraperTool:
    def __init__(self):
        pass
    
    def scrape(self, url):
        loader = WebBaseLoader(url)
        return loader.load()

# Tool 4: Save to .txt file Tool
class SaveToTextFileTool:
    def __init__(self):
        pass
    
    def save(self, filename, content):
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)

# Research AI Agent
class ResearchAgent:
    def __init__(self):
        self.wikipedia_tool = WikipediaSearchTool()
        self.duckduckgo_tool = DuckDuckGoSearchTool()
        self.web_scraper_tool = WebScraperTool()
        self.save_tool = SaveToTextFileTool()
    
    def run(self, query):
        # Step 1: Search in Wikipedia
        print(f"Searching Wikipedia for: {query}")
        wikipedia_result = self.wikipedia_tool.search(query)
        
        # Step 2: If no Wikipedia result, try DuckDuckGo
        if not wikipedia_result:
            print("No results from Wikipedia, searching DuckDuckGo...")
            duckduckgo_results = self.duckduckgo_tool.search(query)
            
            # Step 3: If DuckDuckGo finds a website, scrape the content
            if duckduckgo_results and 'link' in duckduckgo_results[0]:
                url = duckduckgo_results[0]['link']
                print(f"Scraping website: {url}")
                website_content = self.web_scraper_tool.scrape(url)
                full_text = '\n'.join([doc.page_content for doc in website_content])
            else:
                full_text = "No content found from DuckDuckGo search results."
        else:
            full_text = wikipedia_result
        
        # Step 4: Save the result to a .txt file
        filename = "research_result.txt"
        print(f"Saving research to {filename}")
        self.save_tool.save(filename, full_text)
        print(f"Research saved successfully to {filename}")

# Initialize and run the agent
agent = ResearchAgent()
agent.run("Research about the XZ backdoor")

